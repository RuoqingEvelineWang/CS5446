{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        MAP  diastolic_bp  systolic_bp      urine        ALT  \\\n",
      "0           0  67.964940     56.709198   144.578430  241.00052  24.226444   \n",
      "1           1  63.603493     53.635162   143.283780  230.52171  23.933348   \n",
      "2           2  65.750670     56.904236   143.534000  217.76741  21.803823   \n",
      "3           3  44.684580     41.952940   117.236534  291.90466  33.613720   \n",
      "4           4  61.486233     63.960106   111.537060  435.26230  45.407272   \n",
      "\n",
      "         AST        PO2  lactic_acid  serum_creatinine  ...  GCS_total  \\\n",
      "0  23.811718   83.46306     1.477299          0.893153  ...         15   \n",
      "1  30.188170  120.01681     1.733099          0.862924  ...         15   \n",
      "2  26.318861   84.16420     1.375228          0.819521  ...         15   \n",
      "3  24.136852  102.35325     1.252799          0.754315  ...         15   \n",
      "4  23.192320   63.73771     1.845126          1.155209  ...         15   \n",
      "\n",
      "   urine_m  ALT_AST_m  FiO2_m  GCS_total_m  PO2_m  lactic_acid_m  \\\n",
      "0        0          0       0            1      0              0   \n",
      "1        0          0       0            0      0              0   \n",
      "2        0          0       0            0      0              0   \n",
      "3        1          0       0            0      0              0   \n",
      "4        0          0       0            1      0              0   \n",
      "\n",
      "   serum_creatinine_m  PatientID  Timepoints  \n",
      "0                   0          0           0  \n",
      "1                   0          0           1  \n",
      "2                   0          0           2  \n",
      "3                   0          0           3  \n",
      "4                   0          0           4  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C001_FakeHypotension.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#States (of the patient):\n",
    "#MAP: Mean Arterial Pressure. The average pressure in a patient's arteries during one cardiac cycle. It's a key indicator of tissue perfusion in organs.\n",
    "#normal range: 70-100 mmHg\n",
    "#severe risk: below 60\n",
    "\n",
    "#Diastolic BP: Diastolic Blood Pressure. The pressure in the arteries when the heart rests between beats.\n",
    "#normal range: 60-80 mmHg\n",
    "#severe risk: below 40 or above 120\n",
    "\n",
    "#Systolic BP: Systolic Blood Pressure. The pressure in the arteries when the heart beats and pumps blood.\n",
    "#normal range: 90-120 mmHg\n",
    "#severe risk: below 90 or above 180\n",
    "\n",
    "#Urine: Volume of urine output, an important measure of kidney function and fluid balance.\n",
    "#Urine_m: Indicates whether urine measurement is missing.\n",
    "#normal range: 33-83mL per hour (not sure what the time interval is??)\n",
    "\n",
    "#ALT: Alanine Aminotransferase. An enzyme found in the liver, used to assess liver health. Elevated levels indicate liver damage or disease.\n",
    "#normal range: 7-56 U/L\n",
    "#severe risk: above 200\n",
    "#AST: Aspartate Aminotransferase. Another enzyme linked to liver function, often measured with ALT to assess liver damage.\n",
    "#normal range: 10-40 U/L\n",
    "#severe risk: above 200\n",
    "#ALT_AST_m: Indicates whether ALT and AST measurements are missing.\n",
    "\n",
    "\n",
    "#PO2: Partial Pressure Oxygen. The amount of oxygen gas in arterial blood, used to assess a patient's respitory function.\n",
    "#PO2_m: Indicates whether PO2 measurement is missing.\n",
    "#normal range: 75-100 mmHg\n",
    "#severe risk: below 60\n",
    "\n",
    "#Lactic Acid: A product of anaerobic metabolism. Elevated levels can indicate inadequate oxygen delivery to tissues or sepsis.\n",
    "#Lactic_acid_m: Indicates whether lactic acid measurement is missing.\n",
    "#normal range: 0.5-2.2 mmol/L\n",
    "#severe risk: above 4\n",
    "\n",
    "#Serum Creatinine: A waste product filtered by the kidneys. High levels can indicate impaired kidney function.\n",
    "#Serum_creatinine_m: Indicates whether serum creatinine measurement is missing.\n",
    "#normal range: 0.6-1.2 mg/dL\n",
    "#severe risk: above 4\n",
    "\n",
    "#GCS Total: Glasgow Coma Scale Total. A scale that assesses the level of consciousness in a patient based on their verbal, motor, and eye responses.\n",
    "#GCS_total_m: Indicates whether GCS score is missing.\n",
    "#normal range: 15 (fully conscious)\n",
    "#severe risk: 3-7 (comatose)\n",
    "\n",
    "\n",
    "#Actions (of the doctor):\n",
    "#Fluid Boluses: Amount of fluids administered intravenously to manage blood pressure or hydration.\n",
    "\n",
    "#Vasopressors: Medications that constrict blood vessels to increase blood pressure, often used in hypotensive or shock states.\n",
    "\n",
    "#FiO2: Fraction of Inspired Oxygen. The percentage of oxygen in the air mixture that a patient is breathing. Higher levels are used in patients needing more oxygen.\n",
    "#FiO2_m: Indicates whether FiO2 measurements are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 67.96494     56.709198   144.57843    ...   1.7330985    0.8629241\n",
      "   15.        ]\n",
      " [ 63.603493    53.635162   143.28378    ...   1.3752282    0.8195206\n",
      "   15.        ]\n",
      " [ 65.75067     56.904236   143.534      ...   1.2527988    0.75431526\n",
      "   15.        ]\n",
      " ...\n",
      " [ 78.85624     64.86505    123.241035   ...   1.3828557    1.086653\n",
      "   15.        ]\n",
      " [ 74.18521     58.027935   123.97409    ...   1.2868271    0.9677528\n",
      "   15.        ]\n",
      " [ 88.85414     69.937996   125.38483    ...   1.2924969    0.95900583\n",
      "   15.        ]]\n"
     ]
    }
   ],
   "source": [
    "#combine adjacent records into transition (takes 3min to run, can skip and read saved file)\n",
    "#each transition combines 2 rows of data with same PatientID, adjacent Timepoints\n",
    "state_columns = ['MAP', 'diastolic_bp', 'systolic_bp', 'urine', 'ALT', 'AST', 'PO2', 'lactic_acid', 'serum_creatinine', 'GCS_total']\n",
    "action_columns = ['fluid_boluses', 'vasopressors', 'FiO2']\n",
    "\n",
    "def create_transitions(df):\n",
    "    df = df.sort_values(['PatientID', 'Timepoints'])\n",
    "    transitions = []\n",
    "    patients = df['PatientID'].unique()\n",
    "\n",
    "    for patient in patients:\n",
    "        patient_records = df[df['PatientID'] == patient].reset_index(drop=True)\n",
    "        for i in range(len(patient_records) - 1):\n",
    "            current_state = patient_records.iloc[i][state_columns]\n",
    "            next_state = patient_records.iloc[i + 1][state_columns]\n",
    "            action = patient_records.iloc[i][action_columns]\n",
    "            transitions.append(np.concatenate([current_state, action, next_state]))\n",
    "    return np.array(transitions)\n",
    "\n",
    "transitions = create_transitions(df)\n",
    "#print(transitions)\n",
    "\n",
    "transitions_header = ['current_' + x for x in state_columns] + action_columns + ['next_' + x for x in state_columns]\n",
    "transitions_df = pd.DataFrame(transitions, columns=transitions_header)\n",
    "transitions_df.to_csv(\"processed_transitions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read output of above code from file directly\n",
    "transitions_df = pd.read_csv('processed_transitions.csv')\n",
    "transitions = transitions_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize and split data\n",
    "scaler = StandardScaler()\n",
    "scaled_transitions = scaler.fit_transform(transitions)\n",
    "\n",
    "X = scaled_transitions[:, :len(state_columns) + len(action_columns)]\n",
    "y = scaled_transitions[:, len(state_columns) + len(action_columns):]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.6463706493377686\n",
      "epoch: 10, loss: 0.1986122727394104\n",
      "epoch: 20, loss: 0.7940933704376221\n",
      "epoch: 30, loss: 0.2832067608833313\n",
      "epoch: 40, loss: 0.4175243377685547\n",
      "epoch: 50, loss: 0.26314106583595276\n",
      "epoch: 60, loss: 0.540831446647644\n",
      "epoch: 70, loss: 0.8002191781997681\n",
      "epoch: 80, loss: 0.2809102237224579\n",
      "epoch: 90, loss: 0.06554313004016876\n",
      "test loss: 0.5617451667785645\n"
     ]
    }
   ],
   "source": [
    "#use neural network to functionally approximate transitions\n",
    "class TransitionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=128):\n",
    "        super(TransitionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = TransitionModel(input_size=len(state_columns) + len(action_columns), output_size=len(state_columns))\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "batch_size = 16\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    X_train_shuffled_idx = torch.randperm(X_train_tensor.size()[0])\n",
    "    for i in range(0, X_train_tensor.size()[0], batch_size):\n",
    "        idx = X_train_shuffled_idx[i:i + batch_size]\n",
    "        batch_X, batch_y = X_train_tensor[idx], y_train_tensor[idx]\n",
    "        outputs = model(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch: {epoch}, loss: {loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test_loss = loss_function(y_pred, y_test_tensor)\n",
    "    print(f'test loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (Linear Regression): 0.5522047393013321\n",
      "Test Loss (Linear Regression): 0.563679192135602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_test = linear_model.predict(X_test)\n",
    "train_loss = mean_squared_error(y_train, y_pred_train)\n",
    "test_loss = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train Loss (Linear Regression): {train_loss}\")\n",
    "print(f\"Test Loss (Linear Regression): {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (Decision Tree): 0.5323839253554765\n",
      "Test Loss (Decision Tree): 0.5781279933566097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = tree_model.predict(X_train)\n",
    "y_pred_test = tree_model.predict(X_test)\n",
    "\n",
    "train_loss_tree = mean_squared_error(y_train, y_pred_train)\n",
    "test_loss_tree = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train Loss (Decision Tree): {train_loss_tree}\")\n",
    "print(f\"Test Loss (Decision Tree): {test_loss_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "model based approach progress:\n",
    "1. preprocessing of states & actions\n",
    " - currently ignoring the _m columns (indications of missing state measurements)\n",
    "2. function approximation for transitions\n",
    " - tried neural networks, linear regression and decision tree, all have the same loss around 0.5\n",
    " - for neural network, the loss didn't improve from initial epoch, need more work on the architecture & parameter values\n",
    " - consider using multiple previous states instead of just 1 (like atari games)\n",
    " - is it important to consider which transitions are from the same patient?\n",
    " - consider mapping the values to categorical values? (severely low, moderately low, normal, moderately high, severely high)\n",
    "3. design rewards\n",
    " - listed normal range and severe risk range for each state measurement\n",
    " - are some of the measurements more significant than others (eg GCS - measurement of consciousness)?\n",
    " - do we need a terminal reward? is the transition's position in the sequence (eg at the end) important to the reward value?\n",
    "4. extract policy from existing data\n",
    " - not started\n",
    "5. calculate optimal policy with doctor's policy as starting point\n",
    " - not started\n",
    "6. evaluate policy\n",
    " - not started\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
